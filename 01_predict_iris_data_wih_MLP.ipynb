{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3            4\n",
      "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
      "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
      "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
      "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
      "4  5.0  3.6  1.4  0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터셋 생성하기\n",
    "# 데이터셋 불러오기\n",
    "data = pd.read_csv('./dataset/iris.csv.gz', header=None)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Iris-versicolor', 'Iris-virginica', 'Iris-setosa'}\n"
     ]
    }
   ],
   "source": [
    "# 훈련셋과 검증셋 분리\n",
    "X = data.iloc[:, 0:4]\n",
    "y = data.iloc[:, 4]\n",
    "\n",
    "print(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(120, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 원핫 인코딩으로 바꿔준다\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(y)\n",
    "y = e.transform(y)\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 243\n",
      "Trainable params: 243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dir = './model/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "model_filepath = model_dir + 'iris.h5'\n",
    "checkpointer = ModelCheckpoint(filepath=model_filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "# 학습의 자동중단! 3번동안 나아지지 않으면 stop!\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 1.2342 - accuracy: 0.3000\n",
      "Epoch 00001: val_loss improved from inf to 1.04062, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 1.0914 - accuracy: 0.3333 - val_loss: 1.0406 - val_accuracy: 0.3333\n",
      "Epoch 2/200\n",
      "10/12 [========================>.....] - ETA: 0s - loss: 1.0304 - accuracy: 0.3300\n",
      "Epoch 00002: val_loss improved from 1.04062 to 1.00409, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.0251 - accuracy: 0.3333 - val_loss: 1.0041 - val_accuracy: 0.3333\n",
      "Epoch 3/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.9659 - accuracy: 0.4000\n",
      "Epoch 00003: val_loss improved from 1.00409 to 0.97429, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.9915 - accuracy: 0.3333 - val_loss: 0.9743 - val_accuracy: 0.3333\n",
      "Epoch 4/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 1.0148 - accuracy: 0.3000\n",
      "Epoch 00004: val_loss improved from 0.97429 to 0.94767, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.9620 - accuracy: 0.3417 - val_loss: 0.9477 - val_accuracy: 0.3333\n",
      "Epoch 5/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 1.0057 - accuracy: 0.1000\n",
      "Epoch 00005: val_loss improved from 0.94767 to 0.92326, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.9372 - accuracy: 0.3667 - val_loss: 0.9233 - val_accuracy: 0.3333\n",
      "Epoch 6/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 1.0209 - accuracy: 0.0000e+00\n",
      "Epoch 00006: val_loss improved from 0.92326 to 0.90412, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.9184 - accuracy: 0.4750 - val_loss: 0.9041 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.9121 - accuracy: 0.5000\n",
      "Epoch 00007: val_loss improved from 0.90412 to 0.88774, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.8993 - accuracy: 0.5833 - val_loss: 0.8877 - val_accuracy: 0.5333\n",
      "Epoch 8/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.8313 - accuracy: 0.7000\n",
      "Epoch 00008: val_loss improved from 0.88774 to 0.87304, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.8854 - accuracy: 0.6000 - val_loss: 0.8730 - val_accuracy: 0.5333\n",
      "Epoch 9/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.8343 - accuracy: 0.5000\n",
      "Epoch 00009: val_loss improved from 0.87304 to 0.85984, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.8682 - accuracy: 0.6000 - val_loss: 0.8598 - val_accuracy: 0.5333\n",
      "Epoch 10/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.8091 - accuracy: 0.5000\n",
      "Epoch 00010: val_loss improved from 0.85984 to 0.84813, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.8567 - accuracy: 0.6417 - val_loss: 0.8481 - val_accuracy: 0.7000\n",
      "Epoch 11/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.7956 - accuracy: 0.6000\n",
      "Epoch 00011: val_loss improved from 0.84813 to 0.83369, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.8440 - accuracy: 0.7250 - val_loss: 0.8337 - val_accuracy: 0.6333\n",
      "Epoch 12/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.8604 - accuracy: 0.7000\n",
      "Epoch 00012: val_loss improved from 0.83369 to 0.82476, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.8271 - accuracy: 0.7417 - val_loss: 0.8248 - val_accuracy: 0.7333\n",
      "Epoch 13/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.8695 - accuracy: 0.7000\n",
      "Epoch 00013: val_loss improved from 0.82476 to 0.78888, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.8074 - accuracy: 0.8000 - val_loss: 0.7889 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.7265 - accuracy: 0.9000\n",
      "Epoch 00014: val_loss improved from 0.78888 to 0.72975, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7630 - accuracy: 0.8083 - val_loss: 0.7297 - val_accuracy: 0.7667\n",
      "Epoch 15/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.7220 - accuracy: 0.8000\n",
      "Epoch 00015: val_loss improved from 0.72975 to 0.66550, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.7066 - accuracy: 0.8250 - val_loss: 0.6655 - val_accuracy: 0.9000\n",
      "Epoch 16/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.6901 - accuracy: 0.7000\n",
      "Epoch 00016: val_loss improved from 0.66550 to 0.61726, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6532 - accuracy: 0.8583 - val_loss: 0.6173 - val_accuracy: 0.9000\n",
      "Epoch 17/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.5859 - accuracy: 1.0000\n",
      "Epoch 00017: val_loss improved from 0.61726 to 0.58153, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6213 - accuracy: 0.8667 - val_loss: 0.5815 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.6153 - accuracy: 0.8000\n",
      "Epoch 00018: val_loss improved from 0.58153 to 0.55452, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.5914 - accuracy: 0.8250 - val_loss: 0.5545 - val_accuracy: 0.9000\n",
      "Epoch 19/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.5714 - accuracy: 0.8545\n",
      "Epoch 00019: val_loss improved from 0.55452 to 0.52835, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.5669 - accuracy: 0.8583 - val_loss: 0.5284 - val_accuracy: 0.9000\n",
      "Epoch 20/200\n",
      " 7/12 [================>.............] - ETA: 0s - loss: 0.5542 - accuracy: 0.8571\n",
      "Epoch 00020: val_loss improved from 0.52835 to 0.50648, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.5441 - accuracy: 0.8583 - val_loss: 0.5065 - val_accuracy: 0.9000\n",
      "Epoch 21/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.4265 - accuracy: 0.9000\n",
      "Epoch 00021: val_loss improved from 0.50648 to 0.48685, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5247 - accuracy: 0.8667 - val_loss: 0.4869 - val_accuracy: 0.9000\n",
      "Epoch 22/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.5681 - accuracy: 0.8000\n",
      "Epoch 00022: val_loss improved from 0.48685 to 0.46911, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5086 - accuracy: 0.8667 - val_loss: 0.4691 - val_accuracy: 0.9000\n",
      "Epoch 23/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.4313 - accuracy: 1.0000\n",
      "Epoch 00023: val_loss improved from 0.46911 to 0.45403, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4888 - accuracy: 0.8750 - val_loss: 0.4540 - val_accuracy: 0.9000\n",
      "Epoch 24/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.4455 - accuracy: 0.9000\n",
      "Epoch 00024: val_loss improved from 0.45403 to 0.43990, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4747 - accuracy: 0.8917 - val_loss: 0.4399 - val_accuracy: 0.9000\n",
      "Epoch 25/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.4933 - accuracy: 0.7000\n",
      "Epoch 00025: val_loss improved from 0.43990 to 0.42835, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4611 - accuracy: 0.9083 - val_loss: 0.4283 - val_accuracy: 0.9333\n",
      "Epoch 26/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.5344 - accuracy: 0.9000\n",
      "Epoch 00026: val_loss improved from 0.42835 to 0.41488, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4484 - accuracy: 0.9167 - val_loss: 0.4149 - val_accuracy: 0.9000\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/12 [=>............................] - ETA: 0s - loss: 0.4557 - accuracy: 1.0000\n",
      "Epoch 00027: val_loss improved from 0.41488 to 0.40423, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4362 - accuracy: 0.8917 - val_loss: 0.4042 - val_accuracy: 0.9000\n",
      "Epoch 28/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.5483 - accuracy: 0.8000\n",
      "Epoch 00028: val_loss improved from 0.40423 to 0.39532, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4245 - accuracy: 0.9167 - val_loss: 0.3953 - val_accuracy: 0.9333\n",
      "Epoch 29/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.3126 - accuracy: 1.0000\n",
      "Epoch 00029: val_loss improved from 0.39532 to 0.38409, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4144 - accuracy: 0.9250 - val_loss: 0.3841 - val_accuracy: 0.9333\n",
      "Epoch 30/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.4058 - accuracy: 1.0000\n",
      "Epoch 00030: val_loss improved from 0.38409 to 0.37479, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4033 - accuracy: 0.9333 - val_loss: 0.3748 - val_accuracy: 0.9333\n",
      "Epoch 31/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.4694 - accuracy: 0.8000\n",
      "Epoch 00031: val_loss improved from 0.37479 to 0.36643, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3961 - accuracy: 0.9333 - val_loss: 0.3664 - val_accuracy: 0.9333\n",
      "Epoch 32/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.5112 - accuracy: 0.9000\n",
      "Epoch 00032: val_loss improved from 0.36643 to 0.35899, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3856 - accuracy: 0.9500 - val_loss: 0.3590 - val_accuracy: 0.9333\n",
      "Epoch 33/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.4243 - accuracy: 1.0000\n",
      "Epoch 00033: val_loss improved from 0.35899 to 0.35043, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3769 - accuracy: 0.9417 - val_loss: 0.3504 - val_accuracy: 0.9333\n",
      "Epoch 34/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.3647 - accuracy: 1.0000\n",
      "Epoch 00034: val_loss improved from 0.35043 to 0.34276, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3666 - accuracy: 0.9333 - val_loss: 0.3428 - val_accuracy: 0.9333\n",
      "Epoch 35/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.3592 - accuracy: 1.0000\n",
      "Epoch 00035: val_loss improved from 0.34276 to 0.33571, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3595 - accuracy: 0.9500 - val_loss: 0.3357 - val_accuracy: 0.9667\n",
      "Epoch 36/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.3798 - accuracy: 1.0000\n",
      "Epoch 00036: val_loss improved from 0.33571 to 0.32826, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3553 - accuracy: 0.9333 - val_loss: 0.3283 - val_accuracy: 0.9333\n",
      "Epoch 37/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.4264 - accuracy: 0.9000\n",
      "Epoch 00037: val_loss improved from 0.32826 to 0.32135, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3427 - accuracy: 0.9500 - val_loss: 0.3213 - val_accuracy: 0.9667\n",
      "Epoch 38/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.3889 - accuracy: 1.0000\n",
      "Epoch 00038: val_loss improved from 0.32135 to 0.31466, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3360 - accuracy: 0.9667 - val_loss: 0.3147 - val_accuracy: 0.9333\n",
      "Epoch 39/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.3785 - accuracy: 1.0000\n",
      "Epoch 00039: val_loss improved from 0.31466 to 0.30709, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3271 - accuracy: 0.9583 - val_loss: 0.3071 - val_accuracy: 0.9667\n",
      "Epoch 40/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.3380 - accuracy: 0.9000\n",
      "Epoch 00040: val_loss improved from 0.30709 to 0.30082, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3192 - accuracy: 0.9583 - val_loss: 0.3008 - val_accuracy: 0.9667\n",
      "Epoch 41/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.3568 - accuracy: 0.9000\n",
      "Epoch 00041: val_loss improved from 0.30082 to 0.29493, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3102 - accuracy: 0.9583 - val_loss: 0.2949 - val_accuracy: 0.9333\n",
      "Epoch 42/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1930 - accuracy: 1.0000\n",
      "Epoch 00042: val_loss improved from 0.29493 to 0.28783, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3035 - accuracy: 0.9583 - val_loss: 0.2878 - val_accuracy: 0.9667\n",
      "Epoch 43/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.3878 - accuracy: 1.0000\n",
      "Epoch 00043: val_loss improved from 0.28783 to 0.28105, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2961 - accuracy: 0.9667 - val_loss: 0.2810 - val_accuracy: 0.9667\n",
      "Epoch 44/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.3487 - accuracy: 0.8000\n",
      "Epoch 00044: val_loss improved from 0.28105 to 0.27825, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2906 - accuracy: 0.9667 - val_loss: 0.2783 - val_accuracy: 0.9333\n",
      "Epoch 45/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.5228 - accuracy: 0.9000\n",
      "Epoch 00045: val_loss improved from 0.27825 to 0.26900, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2840 - accuracy: 0.9583 - val_loss: 0.2690 - val_accuracy: 0.9667\n",
      "Epoch 46/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2903 - accuracy: 1.0000\n",
      "Epoch 00046: val_loss improved from 0.26900 to 0.26701, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2777 - accuracy: 0.9583 - val_loss: 0.2670 - val_accuracy: 0.9333\n",
      "Epoch 47/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1999 - accuracy: 1.0000\n",
      "Epoch 00047: val_loss improved from 0.26701 to 0.25741, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2667 - accuracy: 0.9667 - val_loss: 0.2574 - val_accuracy: 0.9667\n",
      "Epoch 48/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2576 - accuracy: 0.9000\n",
      "Epoch 00048: val_loss improved from 0.25741 to 0.25192, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2638 - accuracy: 0.9583 - val_loss: 0.2519 - val_accuracy: 0.9667\n",
      "Epoch 49/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2379 - accuracy: 1.0000\n",
      "Epoch 00049: val_loss improved from 0.25192 to 0.24763, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2541 - accuracy: 0.9667 - val_loss: 0.2476 - val_accuracy: 0.9667\n",
      "Epoch 50/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2036 - accuracy: 1.0000\n",
      "Epoch 00050: val_loss improved from 0.24763 to 0.24256, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2508 - accuracy: 0.9667 - val_loss: 0.2426 - val_accuracy: 0.9667\n",
      "Epoch 51/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2660 - accuracy: 0.9000\n",
      "Epoch 00051: val_loss improved from 0.24256 to 0.23627, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2461 - accuracy: 0.9583 - val_loss: 0.2363 - val_accuracy: 0.9667\n",
      "Epoch 52/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2622 - accuracy: 1.0000\n",
      "Epoch 00052: val_loss improved from 0.23627 to 0.23125, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2362 - accuracy: 0.9667 - val_loss: 0.2312 - val_accuracy: 0.9667\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2760 - accuracy: 1.0000\n",
      "Epoch 00053: val_loss improved from 0.23125 to 0.22616, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2297 - accuracy: 0.9833 - val_loss: 0.2262 - val_accuracy: 0.9667\n",
      "Epoch 54/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2827 - accuracy: 1.0000\n",
      "Epoch 00054: val_loss improved from 0.22616 to 0.22578, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2289 - accuracy: 0.9667 - val_loss: 0.2258 - val_accuracy: 0.9667\n",
      "Epoch 55/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2821 - accuracy: 0.8000\n",
      "Epoch 00055: val_loss improved from 0.22578 to 0.21665, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2287 - accuracy: 0.9583 - val_loss: 0.2167 - val_accuracy: 0.9667\n",
      "Epoch 56/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1725 - accuracy: 1.0000\n",
      "Epoch 00056: val_loss did not improve from 0.21665\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2138 - accuracy: 0.9667 - val_loss: 0.2195 - val_accuracy: 0.9667\n",
      "Epoch 57/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.3344 - accuracy: 0.9000\n",
      "Epoch 00057: val_loss improved from 0.21665 to 0.20725, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2083 - accuracy: 0.9667 - val_loss: 0.2072 - val_accuracy: 0.9667\n",
      "Epoch 58/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2082 - accuracy: 1.0000\n",
      "Epoch 00058: val_loss improved from 0.20725 to 0.20322, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2004 - accuracy: 0.9750 - val_loss: 0.2032 - val_accuracy: 0.9667\n",
      "Epoch 59/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1471 - accuracy: 1.0000\n",
      "Epoch 00059: val_loss improved from 0.20322 to 0.20023, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1928 - accuracy: 0.9750 - val_loss: 0.2002 - val_accuracy: 0.9667\n",
      "Epoch 60/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2365 - accuracy: 1.0000\n",
      "Epoch 00060: val_loss improved from 0.20023 to 0.19161, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1841 - accuracy: 0.9750 - val_loss: 0.1916 - val_accuracy: 0.9667\n",
      "Epoch 61/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1644 - accuracy: 1.0000\n",
      "Epoch 00061: val_loss improved from 0.19161 to 0.18582, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1774 - accuracy: 0.9750 - val_loss: 0.1858 - val_accuracy: 0.9667\n",
      "Epoch 62/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2010 - accuracy: 1.0000\n",
      "Epoch 00062: val_loss improved from 0.18582 to 0.18031, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1802 - accuracy: 0.9667 - val_loss: 0.1803 - val_accuracy: 0.9667\n",
      "Epoch 63/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1161 - accuracy: 1.0000\n",
      "Epoch 00063: val_loss did not improve from 0.18031\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1722 - accuracy: 0.9667 - val_loss: 0.1909 - val_accuracy: 0.9667\n",
      "Epoch 64/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.0723 - accuracy: 1.0000\n",
      "Epoch 00064: val_loss improved from 0.18031 to 0.17249, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1630 - accuracy: 0.9833 - val_loss: 0.1725 - val_accuracy: 0.9667\n",
      "Epoch 65/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1614 - accuracy: 1.0000\n",
      "Epoch 00065: val_loss did not improve from 0.17249\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1580 - accuracy: 0.9833 - val_loss: 0.1748 - val_accuracy: 0.9667\n",
      "Epoch 66/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1849 - accuracy: 1.0000\n",
      "Epoch 00066: val_loss improved from 0.17249 to 0.17229, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1563 - accuracy: 0.9667 - val_loss: 0.1723 - val_accuracy: 0.9667\n",
      "Epoch 67/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2468 - accuracy: 0.8000\n",
      "Epoch 00067: val_loss improved from 0.17229 to 0.16394, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1514 - accuracy: 0.9833 - val_loss: 0.1639 - val_accuracy: 0.9667\n",
      "Epoch 68/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1555 - accuracy: 1.0000\n",
      "Epoch 00068: val_loss did not improve from 0.16394\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1523 - accuracy: 0.9667 - val_loss: 0.1751 - val_accuracy: 0.9667\n",
      "Epoch 69/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1083 - accuracy: 1.0000\n",
      "Epoch 00069: val_loss improved from 0.16394 to 0.15825, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1391 - accuracy: 0.9750 - val_loss: 0.1583 - val_accuracy: 0.9667\n",
      "Epoch 70/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1413 - accuracy: 1.0000\n",
      "Epoch 00070: val_loss improved from 0.15825 to 0.15634, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1446 - accuracy: 0.9750 - val_loss: 0.1563 - val_accuracy: 0.9667\n",
      "Epoch 71/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1021 - accuracy: 1.0000\n",
      "Epoch 00071: val_loss did not improve from 0.15634\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1376 - accuracy: 0.9833 - val_loss: 0.1718 - val_accuracy: 0.9667\n",
      "Epoch 72/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.0954 - accuracy: 1.0000\n",
      "Epoch 00072: val_loss improved from 0.15634 to 0.15250, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1371 - accuracy: 0.9750 - val_loss: 0.1525 - val_accuracy: 0.9667\n",
      "Epoch 73/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1658 - accuracy: 0.9000\n",
      "Epoch 00073: val_loss did not improve from 0.15250\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1285 - accuracy: 0.9750 - val_loss: 0.1552 - val_accuracy: 0.9667\n",
      "Epoch 74/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.0867 - accuracy: 1.0000\n",
      "Epoch 00074: val_loss did not improve from 0.15250\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1282 - accuracy: 0.9750 - val_loss: 0.1561 - val_accuracy: 0.9667\n",
      "Epoch 75/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1243 - accuracy: 1.0000\n",
      "Epoch 00075: val_loss improved from 0.15250 to 0.14561, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1234 - accuracy: 0.9833 - val_loss: 0.1456 - val_accuracy: 0.9667\n",
      "Epoch 76/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.0583 - accuracy: 1.0000\n",
      "Epoch 00076: val_loss did not improve from 0.14561\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1194 - accuracy: 0.9833 - val_loss: 0.1528 - val_accuracy: 0.9667\n",
      "Epoch 77/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.0838 - accuracy: 1.0000\n",
      "Epoch 00077: val_loss did not improve from 0.14561\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9750 - val_loss: 0.1477 - val_accuracy: 0.9667\n",
      "Epoch 78/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1027 - accuracy: 1.0000\n",
      "Epoch 00078: val_loss improved from 0.14561 to 0.14425, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1178 - accuracy: 0.9750 - val_loss: 0.1443 - val_accuracy: 0.9667\n",
      "Epoch 79/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1506 - accuracy: 0.9000\n",
      "Epoch 00079: val_loss did not improve from 0.14425\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1126 - accuracy: 0.9833 - val_loss: 0.1470 - val_accuracy: 0.9667\n",
      "Epoch 80/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1530 - accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00080: val_loss improved from 0.14425 to 0.14396, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1110 - accuracy: 0.9750 - val_loss: 0.1440 - val_accuracy: 0.9667\n",
      "Epoch 81/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1122 - accuracy: 1.0000\n",
      "Epoch 00081: val_loss improved from 0.14396 to 0.14201, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1103 - accuracy: 0.9833 - val_loss: 0.1420 - val_accuracy: 0.9667\n",
      "Epoch 82/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1566 - accuracy: 1.0000\n",
      "Epoch 00082: val_loss did not improve from 0.14201\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1157 - accuracy: 0.9750 - val_loss: 0.1505 - val_accuracy: 0.9667\n",
      "Epoch 83/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.0524 - accuracy: 1.0000\n",
      "Epoch 00083: val_loss improved from 0.14201 to 0.13580, saving model to ./model\\iris.h5\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1068 - accuracy: 0.9833 - val_loss: 0.1358 - val_accuracy: 0.9667\n",
      "Epoch 84/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1404 - accuracy: 0.9000\n",
      "Epoch 00084: val_loss did not improve from 0.13580\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1033 - accuracy: 0.9833 - val_loss: 0.1415 - val_accuracy: 0.9667\n",
      "Epoch 85/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.0458 - accuracy: 1.0000\n",
      "Epoch 00085: val_loss did not improve from 0.13580\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1018 - accuracy: 0.9750 - val_loss: 0.1383 - val_accuracy: 0.9667\n",
      "Epoch 86/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.0750 - accuracy: 1.0000\n",
      "Epoch 00086: val_loss did not improve from 0.13580\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9750 - val_loss: 0.1430 - val_accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 학습시키기\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=10, callbacks=[checkpointer, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9667\n",
      "정확도 : 0.97 \n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 평가하기\n",
    "print(\"정확도 : %.2f \" %(model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 학습과정 살펴보기\n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label='val_set_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label='train_set_oss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 학습되는 것을 볼 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
