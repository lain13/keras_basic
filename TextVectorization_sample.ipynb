{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextVectorization_sample.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMn3fBgvawgmoHkmetMXYxR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lain13/keras_basic/blob/master/TextVectorization_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHim4Cby4SjN"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhTJCFIF9CZv"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdSPHziP4bED"
      },
      "source": [
        "text_dataset = tf.data.Dataset.from_tensor_slices([\n",
        "                                                   \"this is some clean text\", \n",
        "                                                   \"some more text\", \n",
        "                                                   \"even some more text\"]) \n",
        "# Fit a TextVectorization layer\n",
        "vectorizer = TextVectorization(max_tokens=10, output_mode='tf-idf',ngrams=None)    \n",
        "vectorizer.adapt(text_dataset.batch(1024))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7H40VJT4ljo",
        "outputId": "1e604c73-9223-4acd-b3b0-4c02f7d3c3e1"
      },
      "source": [
        "# Vector for word \"this\"\n",
        "vectorizer(['this'])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
              "array([[0.        , 0.        , 0.        , 0.        , 0.91629076,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9C-aZn04YlF",
        "outputId": "e8c13200-d98e-40c1-c52b-8cf781057b85"
      },
      "source": [
        "# Pickle the config and weights\n",
        "pickle.dump({'config': vectorizer.get_config(),\n",
        "             'weights': vectorizer.get_weights()}\n",
        "            , open(\"tv_layer.pkl\", \"wb\"))\n",
        "\n",
        "print (\"*\"*10)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**********\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkPSiFIA9deN",
        "outputId": "2f32fb0f-e8d7-4a98-ea35-81500f0aa658"
      },
      "source": [
        "# Later you can unpickle and use \n",
        "# `config` to create object and \n",
        "# `weights` to load the trained weights. \n",
        "\n",
        "from_disk = pickle.load(open(\"tv_layer.pkl\", \"rb\"))\n",
        "new_v = TextVectorization.from_config(from_disk['config'])\n",
        "# You have to call `adapt` with some dummy data (BUG in Keras)\n",
        "new_v.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
        "new_v.set_weights(from_disk['weights'])\n",
        "\n",
        "# Lets see the Vector for word \"this\"\n",
        "print (new_v([\"this\"]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.         0.         0.         0.         0.91629076 0.\n",
            "  0.         0.         0.         0.        ]], shape=(1, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrEuYm_b5zeV"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "data = [\n",
        "    \"The sky is blue.\",\n",
        "    \"Grass is green.\",\n",
        "    \"Hunter2 is my password.\",\n",
        "]\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68mgJsAH51SQ"
      },
      "source": [
        "# Create vectorizer.\n",
        "text_dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "vectorizer = TextVectorization(\n",
        "    max_tokens=100000, output_mode='tf-idf', ngrams=None, name='output_layer'\n",
        ")\n",
        "vectorizer.adapt(text_dataset.batch(1024))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBedmICw65C9",
        "outputId": "a9fd0fd7-7238-4557-8442-5560679fda1c"
      },
      "source": [
        "input = layers.Input(shape=(1, ), dtype=tf.string, name='input_layer')\n",
        "output = vectorizer(input)\n",
        "model = models.Model(input, output)\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "output_layer (TextVectorizat (None, 100000)            0         \n",
            "=================================================================\n",
            "Total params: 100,000\n",
            "Trainable params: 0\n",
            "Non-trainable params: 100,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J27g32W7aZh",
        "outputId": "26a3f253-af9e-4de0-90a4-949dc8476963"
      },
      "source": [
        "# Save.\n",
        "filepath = \"vectorizer-model\"\n",
        "model.save(filepath, save_format=\"tf\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: vectorizer-model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3NfTLKY6BQD",
        "outputId": "54287fe3-1054-4b64-fa0d-e45fb510b532"
      },
      "source": [
        "# Load.\n",
        "loaded_model = tf.keras.models.load_model(filepath)\n",
        "loaded_vectorizer = loaded_model.get_layer('input_layer')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2b1lTQE74Qq",
        "outputId": "83270ccc-5c4d-48b5-d4d3-3f2a765d0f24"
      },
      "source": [
        "dir(loaded_model)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_TF_MODULE_IGNORED_PROPERTIES',\n",
              " '__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_activity_regularizer',\n",
              " '_add_trackable',\n",
              " '_add_variable_with_custom_getter',\n",
              " '_assert_compile_was_called',\n",
              " '_assert_weights_created',\n",
              " '_auto_track_sub_layers',\n",
              " '_autocast',\n",
              " '_autographed_call',\n",
              " '_base_model_initialized',\n",
              " '_build_input_shape',\n",
              " '_call_accepts_kwargs',\n",
              " '_call_arg_was_passed',\n",
              " '_call_fn_arg_defaults',\n",
              " '_call_fn_arg_positions',\n",
              " '_call_fn_args',\n",
              " '_call_full_argspec',\n",
              " '_callable_losses',\n",
              " '_cast_single_input',\n",
              " '_check_call_args',\n",
              " '_checkpoint_dependencies',\n",
              " '_clear_losses',\n",
              " '_compile_was_called',\n",
              " '_compiled_trainable_state',\n",
              " '_compute_dtype',\n",
              " '_compute_dtype_object',\n",
              " '_compute_output_and_mask_jointly',\n",
              " '_compute_tensor_usage_count',\n",
              " '_configure_steps_per_execution',\n",
              " '_conform_to_reference_input',\n",
              " '_dedup_weights',\n",
              " '_default_training_arg',\n",
              " '_deferred_dependencies',\n",
              " '_distribution_strategy',\n",
              " '_dtype',\n",
              " '_dtype_policy',\n",
              " '_dynamic',\n",
              " '_eager_losses',\n",
              " '_enable_dict_to_input_mapping',\n",
              " '_expects_mask_arg',\n",
              " '_expects_training_arg',\n",
              " '_feed_input_names',\n",
              " '_feed_input_shapes',\n",
              " '_feed_inputs',\n",
              " '_flatten',\n",
              " '_flatten_layers',\n",
              " '_flatten_to_reference_inputs',\n",
              " '_functional_construction_call',\n",
              " '_gather_children_attribute',\n",
              " '_gather_saveables_for_checkpoint',\n",
              " '_get_call_arg_value',\n",
              " '_get_callback_model',\n",
              " '_get_compile_args',\n",
              " '_get_distribution_strategy',\n",
              " '_get_existing_metric',\n",
              " '_get_input_masks',\n",
              " '_get_node_attribute_at_index',\n",
              " '_get_optimizer',\n",
              " '_get_save_spec',\n",
              " '_get_trainable_state',\n",
              " '_graph_network_add_loss',\n",
              " '_graph_network_add_metric',\n",
              " '_handle_activity_regularization',\n",
              " '_handle_deferred_dependencies',\n",
              " '_handle_deferred_layer_dependencies',\n",
              " '_handle_weight_regularization',\n",
              " '_in_multi_worker_mode',\n",
              " '_inbound_nodes',\n",
              " '_inbound_nodes_value',\n",
              " '_infer_output_signature',\n",
              " '_init_batch_counters',\n",
              " '_init_call_fn_args',\n",
              " '_init_graph_network',\n",
              " '_init_set_name',\n",
              " '_initial_weights',\n",
              " '_input_coordinates',\n",
              " '_input_layers',\n",
              " '_input_spec',\n",
              " '_insert_layers',\n",
              " '_instrument_layer_creation',\n",
              " '_instrumented_keras_api',\n",
              " '_instrumented_keras_layer_class',\n",
              " '_instrumented_keras_model_class',\n",
              " '_is_compiled',\n",
              " '_is_graph_network',\n",
              " '_is_layer',\n",
              " '_is_model_for_instrumentation',\n",
              " '_keras_api_names',\n",
              " '_keras_api_names_v1',\n",
              " '_keras_tensor_symbolic_call',\n",
              " '_layer_call_argspecs',\n",
              " '_layer_checkpoint_dependencies',\n",
              " '_layers',\n",
              " '_list_extra_dependencies_for_serialization',\n",
              " '_list_functions_for_serialization',\n",
              " '_lookup_dependency',\n",
              " '_losses',\n",
              " '_map_resources',\n",
              " '_maybe_build',\n",
              " '_maybe_cast_inputs',\n",
              " '_maybe_create_attribute',\n",
              " '_maybe_initialize_trackable',\n",
              " '_maybe_load_initial_epoch_from_ckpt',\n",
              " '_metrics',\n",
              " '_metrics_lock',\n",
              " '_must_restore_from_config',\n",
              " '_name',\n",
              " '_name_based_attribute_restore',\n",
              " '_name_based_restores',\n",
              " '_name_scope',\n",
              " '_nested_inputs',\n",
              " '_nested_outputs',\n",
              " '_network_nodes',\n",
              " '_no_dependency',\n",
              " '_nodes_by_depth',\n",
              " '_non_trainable_weights',\n",
              " '_obj_reference_counts',\n",
              " '_obj_reference_counts_dict',\n",
              " '_object_identifier',\n",
              " '_outbound_nodes',\n",
              " '_outbound_nodes_value',\n",
              " '_output_coordinates',\n",
              " '_output_layers',\n",
              " '_output_mask_cache',\n",
              " '_output_shape_cache',\n",
              " '_output_tensor_cache',\n",
              " '_predict_counter',\n",
              " '_preload_simple_restoration',\n",
              " '_preserve_input_structure_in_config',\n",
              " '_reset_compile_cache',\n",
              " '_restore_from_checkpoint_position',\n",
              " '_run_eagerly',\n",
              " '_run_internal_graph',\n",
              " '_saved_model_inputs_spec',\n",
              " '_self_name_based_restores',\n",
              " '_self_saveable_object_factories',\n",
              " '_self_setattr_tracking',\n",
              " '_self_unconditional_checkpoint_dependencies',\n",
              " '_self_unconditional_deferred_dependencies',\n",
              " '_self_unconditional_dependency_names',\n",
              " '_self_update_uid',\n",
              " '_serialized_attributes',\n",
              " '_set_call_arg_value',\n",
              " '_set_connectivity_metadata',\n",
              " '_set_dtype_policy',\n",
              " '_set_inputs',\n",
              " '_set_mask_keras_history_checked',\n",
              " '_set_mask_metadata',\n",
              " '_set_output_names',\n",
              " '_set_save_spec',\n",
              " '_set_trainable_state',\n",
              " '_set_training_mode',\n",
              " '_setattr_tracking',\n",
              " '_should_cast_single_input',\n",
              " '_should_compute_mask',\n",
              " '_should_eval',\n",
              " '_single_restoration_from_checkpoint_position',\n",
              " '_split_out_first_arg',\n",
              " '_stateful',\n",
              " '_steps_per_execution',\n",
              " '_supports_masking',\n",
              " '_symbolic_call',\n",
              " '_tensor_usage_count',\n",
              " '_test_counter',\n",
              " '_tf_api_names',\n",
              " '_tf_api_names_v1',\n",
              " '_thread_local',\n",
              " '_track_trackable',\n",
              " '_trackable_saved_model_saver',\n",
              " '_trackable_saver',\n",
              " '_tracking_metadata',\n",
              " '_train_counter',\n",
              " '_trainable',\n",
              " '_trainable_weights',\n",
              " '_training_state',\n",
              " '_unconditional_checkpoint_dependencies',\n",
              " '_unconditional_dependency_names',\n",
              " '_undeduplicated_weights',\n",
              " '_update_uid',\n",
              " '_updated_config',\n",
              " '_updates',\n",
              " '_validate_compile',\n",
              " '_validate_graph_inputs_and_outputs',\n",
              " 'activity_regularizer',\n",
              " 'add_loss',\n",
              " 'add_metric',\n",
              " 'add_update',\n",
              " 'add_variable',\n",
              " 'add_weight',\n",
              " 'apply',\n",
              " 'build',\n",
              " 'built',\n",
              " 'call',\n",
              " 'compile',\n",
              " 'compiled_loss',\n",
              " 'compiled_metrics',\n",
              " 'compute_dtype',\n",
              " 'compute_mask',\n",
              " 'compute_output_shape',\n",
              " 'compute_output_signature',\n",
              " 'count_params',\n",
              " 'distribute_strategy',\n",
              " 'dtype',\n",
              " 'dtype_policy',\n",
              " 'dynamic',\n",
              " 'evaluate',\n",
              " 'evaluate_generator',\n",
              " 'fit',\n",
              " 'fit_generator',\n",
              " 'from_config',\n",
              " 'get_config',\n",
              " 'get_input_at',\n",
              " 'get_input_mask_at',\n",
              " 'get_input_shape_at',\n",
              " 'get_layer',\n",
              " 'get_losses_for',\n",
              " 'get_output_at',\n",
              " 'get_output_mask_at',\n",
              " 'get_output_shape_at',\n",
              " 'get_updates_for',\n",
              " 'get_weights',\n",
              " 'graph_debug_info',\n",
              " 'history',\n",
              " 'inbound_nodes',\n",
              " 'input',\n",
              " 'input_mask',\n",
              " 'input_names',\n",
              " 'input_shape',\n",
              " 'input_spec',\n",
              " 'inputs',\n",
              " 'layers',\n",
              " 'load_weights',\n",
              " 'losses',\n",
              " 'make_predict_function',\n",
              " 'make_test_function',\n",
              " 'make_train_function',\n",
              " 'metrics',\n",
              " 'metrics_names',\n",
              " 'name',\n",
              " 'name_scope',\n",
              " 'non_trainable_variables',\n",
              " 'non_trainable_weights',\n",
              " 'optimizer',\n",
              " 'outbound_nodes',\n",
              " 'output',\n",
              " 'output_mask',\n",
              " 'output_names',\n",
              " 'output_shape',\n",
              " 'outputs',\n",
              " 'predict',\n",
              " 'predict_function',\n",
              " 'predict_generator',\n",
              " 'predict_on_batch',\n",
              " 'predict_step',\n",
              " 'reset_metrics',\n",
              " 'reset_states',\n",
              " 'run_eagerly',\n",
              " 'save',\n",
              " 'save_weights',\n",
              " 'set_weights',\n",
              " 'signatures',\n",
              " 'state_updates',\n",
              " 'stateful',\n",
              " 'stop_training',\n",
              " 'submodules',\n",
              " 'summary',\n",
              " 'supports_masking',\n",
              " 'tensorflow_git_version',\n",
              " 'tensorflow_version',\n",
              " 'test_function',\n",
              " 'test_on_batch',\n",
              " 'test_step',\n",
              " 'to_json',\n",
              " 'to_yaml',\n",
              " 'train_function',\n",
              " 'train_on_batch',\n",
              " 'train_step',\n",
              " 'trainable',\n",
              " 'trainable_variables',\n",
              " 'trainable_weights',\n",
              " 'updates',\n",
              " 'variable_dtype',\n",
              " 'variables',\n",
              " 'weights',\n",
              " 'with_name_scope']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-YAdP7S76oP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}